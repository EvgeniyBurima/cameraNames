<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <title>Focus distances</title>
    <link rel="stylesheet" href="./dist/css/mvp.css">
    <style>
        body {
            background-color: antiquewhite;
        }

        .wrapper {
            padding: 8px;
        }

        video {
            max-width: 100%;
        }

        .label {
            display: flex;
            gap: 8px;
            align-items: center;
        }

        .label input {
            padding: 0;
            margin: 0;
        }
    </style>
</head>

<body>
<div class="wrapper">
    <h2>Focus Distance Test</h2>
    <video autoplay playsinline muted class="video"></video>
    <div class="label">
        <input type="range" id="focus-distance" name="focus-distance" min="0" max="100" value="90" step="1">
        <label for="focus-distance">Focus Distance</label>
    </div>
    <div class="label">
        <b>Blur score</b>
        <span id="blur-score">1</span>
    </div>
    <button id="autofocus-btn">autofocus</button>
    <canvas id="canvas" hidden></canvas>
</div>

<script type="module">
  import PDF417 from './dist/cores/libpdf417.js';
  import Blur from './dist/cores/blurCore.js';

  const { pdf417key } = JSON.parse(
    atob('eyJwZGY0MTdrZXkiOiJtUlNlZTlFV0dmRGt1UWxwRG1oRU1UQzBoeEJqblVqVEhidkgxbjAzc1dYa0NzQzJhYmRrcm0yOW1xeWhScjlpcXRqR1h1aXZyZnBoQ3dIZ3hjaFZoVVVDYjMwRkNteWtnRmdFdkJrcFBWLzcwY2R4K3dKbFZ3UnVsSlU5cUE2VHZtZWhleGh3K1E2Zmd5RmM2UXdnRjNDTzdxTjM2dUxBS211SFpzeEpmb1E9IiwiaW1hZ2VQcm9jZXNzaW5nS2V5IjoieGpjazNxTzhmdEo1K3BnRkVEaVdRTjVXWXRqRDZ4TnlYZnpEY005UGtaMTVyaGY0OWNpN0wxeERTWkZ2RHhSUlByMWo3cTNscWIrRUxnbGpWNjVWTWc1d2IyN2hONS8rWXZ4UjRta2ZNVHVQQ0ZWdm5FN2tENjFpVGcxRVhPUHZ0cUlyYUc4SGxwRjdQZXZmYzQ3Y1g5RHMxU0svZHNmeDh4T2hEdUcrSVdNPSIsInRyYWNrU3RyaW5nUGFyc2VyS2V5Ijoic2NlMjRsZGhHVmdERExjMDFEenNmaXloMWFMUWtpM0ZLR09ra0xYa2JQU2M0YXQ2a3BDbFFwUzRKdzVWWlh6WVl4bk9RR2gzcUhUNS9mMWRRbjNnbG9tMDZlbXR2eFlNbzVQcjg3eVowMC9nRm05a3MzdDRJUFBFanJtWGtmNmlmeHZna2RGUHZBOGQ4OTJQR1ltUFlOeVp5UzJlY21aUXN0R3prQTRFSTFzPSIsImNvbW1vbkxpY2Vuc2VLZXkiOiJsUjAzYzZwaVlEMlVtY29WdUV0MDZVbFF2OHR5Zis2K1kwZHNKcTBjbUljTEp1bHc2a2VvMmQ0RDRaZ1lxZFRVeXhNZE5rbzdtdVAxZ1J0NnJFMEF0emNQdC9oaHQ3amlvRTZ2Q3ByZWdsd2RsWW1DcTcyb1ZEUEF3dGVDNzNtQnk0MWdUc0RURDFpck1qYlhhYWlQdWw5R1Y2MEg5Y2RrOUZCci9iRU9RNHM9In0=')
  );
  const video = document.querySelector('video');
  const range = document.getElementById('focus-distance');
  const canvas = document.getElementById('canvas');
  const ctx = canvas.getContext('2d');

  const autofocusBtn = document.getElementById('autofocus-btn');
  const blurScore = document.getElementById('blur-score');

  const rangeParams = {
    min: 0,
    max: 100,
    step: 1,
    val: 90,
    middle: 50,
  }

  let mediastream = null;
  let track = null;
  let width = 0;
  let height = 0;

  let pdfSrc = null;
  let pdfReader = null;
  let pdfCore = null;

  let blurModule = null;

  let time = null;

  let isAutofocus = false

  video.srcObject = mediastream;

  /**
   * all available cameras
   */
  const cameraObjects = [];

  autofocusBtn.addEventListener('click', () => {
    isAutofocus = !isAutofocus;
    if (isAutofocus) {
      autofocus();
    }
  })

  const stopTrack = (mediaStream) => {
    mediaStream.getTracks().forEach((track) => {
      track.stop();
      mediaStream.removeTrack(track);
    });
  };

  const uselessCameras = ['wide', 'telephoto', 'desk'];

  const backCameraKeywords = [
    'desk',
    'rear',
    'back',
    'rück',
    'arrière',
    'trasera',
    'trás',
    'traseira',
    'posteriore',
    '后面',
    '後面',
    '背面',
    '后置',
    '後置',
    '背置',
    'задней',
    'الخلفية',
    '후',
    'arka',
    'achterzijde',
    'หลัง',
    'baksidan',
    'bagside',
    'sau',
    'bak',
    'tylny',
    'takakamera',
    'belakang',
    'אחורית',
    'πίσω',
    'spate',
    'hátsó',
    'zadní',
    'darrere',
    'zadná',
    'задня',
    'stražnja',
    'belakang',
    'बैक',
  ];

  const isBackCameraLabel = (cameraLabel) => {
    const lowerCameraLabel = cameraLabel.toLowerCase();
    return backCameraKeywords.some(
      (backCameraKeyword) => lowerCameraLabel.includes(backCameraKeyword),
    );
  };

  const fillVideoDevices = async () => {
    try {
      let devices = await navigator.mediaDevices.enumerateDevices();
      // if permission is not given, label of video devices will be empty string
      const isPermissionNotGranted = devices
        .filter(({ kind }) => kind.toLowerCase().startsWith('video')) // filter only video devices
        .every(({ label }) => label === '');
      if (isPermissionNotGranted) {
        const stream = await navigator.mediaDevices.getUserMedia({
          video: true,
          audio: false,
        });
        // enumerate devices again - now the label field should be non-empty,
        // as we have a stream active (even if we didn't get persistent permission for camera)
        devices = await navigator.mediaDevices.enumerateDevices();
        stopTrack(stream);
      }

      devices
        .filter(({ kind }) => kind.toLowerCase().startsWith('video')) // filter only video devices
        .filter(({ label }) => {
          const lowerCameraLabel = label.toLowerCase();
          return uselessCameras
            .every((uselessCamera) => !lowerCameraLabel.includes(uselessCamera));
        }) // filter only uselessCamera cameras
        .forEach((videoDevice) => {
          const label = videoDevice.label || '';
          // eslint-disable-next-line no-param-reassign
          videoDevice.cameraType = isBackCameraLabel(label)
            ? 'environment'
            : 'user';
          if (label) {
            cameraObjects.push(videoDevice);
          }
        });
    } catch (error) {
      console.log(error)
      alert(error.message);
    }
  };

  const selectCamera = async (cameraType) => {
    if (!cameraObjects.length) {
      await fillVideoDevices();
    }
    if (!cameraObjects.length) {
      return false;
    }

    let cameraPool = cameraObjects
      .filter(({ cameraType: type }) => type === cameraType)
    if (!cameraPool.length) {
      cameraPool = cameraObjects;
    }

    // sort camera pool by label
    cameraPool = cameraPool
      .sort((camera1, camera2) => camera1.label.localeCompare(camera2.label));

    // Check if cameras are labeled with resolution information,
    // take the higher-resolution one in that case
    // Otherwise pick the first camera
    let selectedCameraIndex = 0;
    const cameraResolutions = cameraPool.map(({ label }) => {
      const match = label.match(/\b([0-9]+)MP?\b/i);
      return match !== null ? parseInt(match[1], 10) : NaN;
    });

    if (!cameraResolutions.some(Number.isNaN)) {
      selectedCameraIndex = cameraResolutions.lastIndexOf(Math.max(...cameraResolutions));
    }

    return cameraPool[selectedCameraIndex];
  };

  const changeFocus = (val) => {
    if (!track) { throw new Error('Track is undefined'); }
    return track.applyConstraints({
      advanced: [{
        focusMode: "manual",
        focusDistance: val,
      }]
    });
  }

  const initTrack = () => {
    [track] = mediastream.getTracks();
    const capabilities = track.getCapabilities();

    if (!capabilities.hasOwnProperty('focusDistance')) { throw new Error('Your device doesnt support focus distance change') }

    width = capabilities.width.max;
    height = capabilities.height.max;

    const { max, min, step } = capabilities.focusDistance;
    range.max = max;
    range.min = min;
    range.step = step;
    rangeParams.max = max;
    rangeParams.min = min;
    rangeParams.sep = step;
    rangeParams.middle = Math.trunc((max - min) / 2);
  };

  const startCamera = async () => {
    try {
      const selectedCamera = await selectCamera('environment')
      mediastream = await navigator.mediaDevices.getUserMedia({
        audio: false,
        video: {
          facingMode: 'environment',
          deviceId: { exact: selectedCamera.deviceId },
        },
      });

      video.srcObject = mediastream;

      initTrack();

    } catch (e) {
      console.log(e)
      alert(e.message)
    }
  }

  range.addEventListener('change', (e) => {
    changeFocus(e.target.value).then(() => {
      const conf = getBlurConfidence();
      if (conf === 0) {
        const pdfRes = readPdf();
        console.log(pdfRes)
        if (pdfRes.data) {
          alert("We've caught your pdf")
        }
      }
    })
  })

  const initBlur = async () => {
    blurModule = await Blur();
  }

  const initPdfModule = async () => {
    pdfCore = await PDF417();
    pdfReader = new pdfCore.PDF417Reader(pdf417key);
    const maxP = 1300;
    pdfSrc = pdfCore._malloc(4 * maxP * maxP);
  };

  /**
   *  0 - image not blurred,
   *  1 - image blurred.
   * @return {boolean|*}
   */
  const getBlurConfidence = () => {
    if (!blurModule) { return 1; }
    const iData = getCenterFrame();
    const confidence = blurModule.BlurAnalyticDetectWASM(
      iData.data,
      iData.width,
      iData.height,
    );
    blurScore.textContent = (1 - confidence) * 100;
    return confidence;
  };

  const getFrame = () => {
    canvas.width = width;
    canvas.height = height;
    ctx.drawImage(video, 0, 0, width, height);
    return ctx.getImageData(0, 0, width, height);
  }

  const getCenterFrame = () => {
    ctx.drawImage(video, 0, 0, 640, 480 );
    return ctx.getImageData(100, 100, 200, 200);
  }

  const readPdf = () => {
    pdfReader.reset();
    const iData = getFrame();
    pdfCore.HEAPU8.set(iData.data, pdfSrc);
    return pdfReader.processImage(
      pdfSrc,
      iData.width,
      iData.height,
      4 * iData.width,
      pdfCore.EImageFormat.RGBA,
    );
  }

  const autofocus = () => {
    if (!isAutofocus) return;
    try {
        if (!time) {
          time = Date.now();
        }
        if (Date.now() - time < 100) {
            window.requestAnimationFrame(autofocus);
            return;
        }
        time = Date.now();
        const conf = getBlurConfidence();
        if (conf === 0) {
          const pdfRes = readPdf();
          console.log(pdfRes)
          if (pdfRes.data) {
            alert("We've caught your pdf")
            return;
          }
        }
        rangeParams.val = rangeParams.val < rangeParams.middle ? rangeParams.max : rangeParams.val - rangeParams.step;
        range.value = rangeParams.val;
        changeFocus(rangeParams.val)
        window.requestAnimationFrame(autofocus);
    } catch {
      window.requestAnimationFrame(autofocus);
    }
  };

  startCamera().then(() => {
      initPdfModule();
      initBlur();
  });


</script>
</body>

</html>
